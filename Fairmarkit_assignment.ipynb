{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sys import platform as sys_pf\n",
    "from cleanco import cleanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.ExcelFile(\"ML_TASK_DATASET.xlsx\",  sheet_name=None)\n",
    "\n",
    "dfs = {sheet_name: df.parse(sheet_name)\n",
    "          for sheet_name in df.sheet_names}\n",
    "\n",
    "data = dfs['Sheet1']\n",
    "\n",
    "# Single word tokens\n",
    "single = ['llc', 'inc', 's.c']\n",
    "Double = ['group corporation', 'production llc', 'electronics usa', 'international corp', 'international corporation']\n",
    "static = ['sderldecv'] # for row no 13\n",
    "\n",
    "df1 = data.copy() # prefer to work on the copy of the original data\n",
    "\n",
    "# get the similar looking company names in one bucket and map all of them to smallest among all.\n",
    "\n",
    "# create the dictionary that matches list of companies with the smalles among all of them\n",
    "\n",
    "df1.sort_values('raw_title',inplace=True, ascending=True)\n",
    "\n",
    "# sorting helped a lot\n",
    "\n",
    "# group similar looking names in their own column containing only the first word of the raw_title\n",
    "# search for this first word in the raw_titles if found then this first word is the true alias\n",
    "# else i am thinking about the distance between two strings\n",
    "\n",
    "# do both of the operations above on the sorted slices for example slice of the column similar_names based on the same name and perform operations on that.\n",
    "columns = ['raw_title', 'unified_title', 'SimilarNames']\n",
    "raw_titles_sorted = df1['raw_title'].values\n",
    "dfop = pd.DataFrame()\n",
    "writer = pd.ExcelWriter('output.xlsx')  # for writing into the excel file\n",
    "similar_looking_names = []\n",
    "for i in range(len(raw_titles_sorted)):\n",
    "    tokens = raw_titles_sorted[i].split()\n",
    "    similar_looking_names.append(tokens[0].replace(',', \"\"))\n",
    "\n",
    "df1['SimilarNames'] = similar_looking_names\n",
    "unique_similar_names = list(set(similar_looking_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiteshsantwani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/hiteshsantwani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(unique_similar_names)):\n",
    "    dfTemp = df1.loc[df1['SimilarNames'] == unique_similar_names[i]]\n",
    "    if dfTemp[\"raw_title\"].values.__contains__(unique_similar_names[i]):\n",
    "        listUnified = []\n",
    "        for j in range(len(dfTemp[\"raw_title\"].values)):\n",
    "            listUnified.append(unique_similar_names[i])\n",
    "        dfTemp[\"unified_title\"] = listUnified\n",
    "        dfop = dfop.append(dfTemp, ignore_index=True)\n",
    "\n",
    "    else:\n",
    "        tempValues = []\n",
    "\n",
    "        for j in range(len(dfTemp[\"raw_title\"].values)):\n",
    "        # Iterate over each row and assign the cleaned name to the unified_title\n",
    "        # aleways check for static first\n",
    "            tokens = dfTemp[\"raw_title\"].values[j].split(\",\")\n",
    "            tokens1 = dfTemp[\"raw_title\"].values[j].rsplit(' ')\n",
    "            if single.__contains__(tokens[len(tokens) - 1].lower()):\n",
    "                tempValues.append(tokens[0].strip(','))\n",
    "        # first trim based on \",\"\n",
    "        # get the last word and check if it contains in the single list\n",
    "            elif Double.__contains__(tokens1[-2].lower() + \" \" + tokens1[-1].lower()):\n",
    "                tempValues.append(tokens1[0].strip(','))\n",
    "        # now trim based on \" \"\n",
    "        # get last two words, add them and check the resultant string in Double list. if yes remove last two else\n",
    "            elif single.__contains__(tokens1[-1].lower()):\n",
    "                tempValues.append(tokens1[0] + \" \" + tokens1[1])\n",
    "        # get last word check it in single list if yes remove it.\n",
    "            else:\n",
    "                tempValues.append(dfTemp[\"raw_title\"].values[j])\n",
    "        # the company is cleaned already\n",
    "        dfTemp[\"unified_title\"] = tempValues\n",
    "        dfop = dfop.append(dfTemp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Cleanco as the further processing step\n",
    "\n",
    "cleancoList = []\n",
    "unified = dfop['unified_title'].values\n",
    "for i in range(len(unified)):\n",
    "    x = cleanco(unified[i])\n",
    "    cleancoList.append(x.clean_name())\n",
    "\n",
    "dfop['unified_title'] = cleancoList    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfop.drop('SimilarNames', axis=1)\n",
    "writer = pd.ExcelWriter('output.xlsx')  # for writing into the excel file\n",
    "dfop.to_excel(writer,'Sheet1')\n",
    "\n",
    "writer.save() # committing the changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
